{"content":"version 1.0\n\n## Copyright Broad Institute, 2019\n## \n## The haplotypecaller-gvcf-gatk4 workflow runs the HaplotypeCaller tool\n## from GATK4 in GVCF mode on a single sample according to GATK Best Practices.\n## When executed the workflow scatters the HaplotypeCaller tool over a sample\n## using an intervals list file. The output file produced will be a\n## single gvcf file which can be used by the joint-discovery workflow.\n##\n## Requirements/expectations :\n## - One analysis-ready BAM file for a single sample (as identified in RG:SM)\n## - Set of variant calling intervals lists for the scatter, provided in a file\n##\n## Outputs :\n## - One GVCF file and its index\n##\n## Cromwell version support \n## - Successfully tested on v53\n##\n## Runtime parameters are optimized for Broad's Google Cloud Platform implementation.\n##\n## LICENSING : \n## This script is released under the WDL source code license (BSD-3) (see LICENSE in \n## https://github.com/broadinstitute/wdl). Note however that the programs it calls may \n## be subject to different licenses. Users are responsible for checking that they are\n## authorized to run all programs before running this script. Please see the dockers\n## for detailed licensing information pertaining to the included programs.\n\n# WORKFLOW DEFINITION \nworkflow HaplotypeCallerGvcf_GATK4 {\n  input {\n    File input_bam\n    File input_bam_index\n    File ref_dict\n    File ref_fasta\n    File ref_fasta_index\n    File scattered_calling_intervals_list\n  \n    Boolean make_gvcf = true\n    Boolean make_bamout = false\n    String gatk_docker = \"us.gcr.io/broad-gatk/gatk:4.2.0.0\"\n    String gatk_path = \"/gatk/gatk\"\n    String gitc_docker = \"us.gcr.io/broad-gotc-prod/genomes-in-the-cloud:2.4.7-1603303710\"\n    String samtools_path = \"samtools\"\n  }  \n\n    Array[File] scattered_calling_intervals = read_lines(scattered_calling_intervals_list)\n\n    #is the input a cram file?\n    Boolean is_cram = sub(basename(input_bam), \".*\\\\.\", \"\") == \"cram\"\n\n    String sample_basename = if is_cram then  basename(input_bam, \".cram\") else basename(input_bam, \".bam\")\n    String vcf_basename = sample_basename\n    String output_suffix = if make_gvcf then \".g.vcf.gz\" else \".vcf.gz\"\n    String output_filename = vcf_basename + output_suffix\n\n    # We need disk to localize the sharded input and output due to the scatter for HaplotypeCaller.\n    # If we take the number we are scattering by and reduce by 20 we will have enough disk space\n    # to account for the fact that the data is quite uneven across the shards.\n    Int potential_hc_divisor = length(scattered_calling_intervals) - 20\n    Int hc_divisor = if potential_hc_divisor > 1 then potential_hc_divisor else 1\n\n  if ( is_cram ) {\n    call CramToBamTask {\n      input:\n        input_cram = input_bam,\n        sample_name = sample_basename,\n        ref_dict = ref_dict,\n        ref_fasta = ref_fasta,\n        ref_fasta_index = ref_fasta_index,\n        docker = gitc_docker,\n        samtools_path = samtools_path\n    }\n  }\n\n  # Call variants in parallel over grouped calling intervals\n  scatter (interval_file in scattered_calling_intervals) {\n\n    # Generate GVCF by interval\n    call HaplotypeCaller {\n      input:\n        input_bam = select_first([CramToBamTask.output_bam, input_bam]),\n        input_bam_index = select_first([CramToBamTask.output_bai, input_bam_index]),\n        interval_list = interval_file,\n        output_filename = output_filename,\n        ref_dict = ref_dict,\n        ref_fasta = ref_fasta,\n        ref_fasta_index = ref_fasta_index,\n        hc_scatter = hc_divisor,\n        make_gvcf = make_gvcf,\n        make_bamout = make_bamout,\n        docker = gatk_docker,\n        gatk_path = gatk_path\n    }\n  }\n\n  # Merge per-interval GVCFs\n  call MergeGVCFs {\n    input:\n      input_vcfs = HaplotypeCaller.output_vcf,\n      input_vcfs_indexes = HaplotypeCaller.output_vcf_index,\n      output_filename = output_filename,\n      docker = gatk_docker,\n      gatk_path = gatk_path\n  }\n\n  # Outputs that will be retained when execution is complete\n  output {\n    File output_vcf = MergeGVCFs.output_vcf\n    File output_vcf_index = MergeGVCFs.output_vcf_index\n  }\n}\n\n# TASK DEFINITIONS\n\ntask CramToBamTask {\n  input {\n    # Command parameters\n    File ref_fasta\n    File ref_fasta_index\n    File ref_dict\n    File input_cram\n    String sample_name\n\n    # Runtime parameters\n    String docker\n    Int? machine_mem_gb\n    Int? disk_space_gb\n    Boolean use_ssd = false\n    Int? preemptible_attempts\n    String samtools_path\n  }\n    Float output_bam_size = size(input_cram, \"GB\") / 0.60\n    Float ref_size = size(ref_fasta, \"GB\") + size(ref_fasta_index, \"GB\") + size(ref_dict, \"GB\")\n    Int disk_size = ceil(size(input_cram, \"GB\") + output_bam_size + ref_size) + 20\n  \n  command {\n    set -e\n    set -o pipefail\n\n    ~{samtools_path} view -h -T ~{ref_fasta} ~{input_cram} |\n    ~{samtools_path} view -b -o ~{sample_name}.bam -\n    ~{samtools_path} index -b ~{sample_name}.bam\n    mv ~{sample_name}.bam.bai ~{sample_name}.bai\n  }\n  runtime {\n    docker: docker\n    memory: select_first([machine_mem_gb, 15]) + \" GB\"\n    disks: \"local-disk \" + select_first([disk_space_gb, disk_size]) + if use_ssd then \" SSD\" else \" HDD\"\n    preemptible: select_first([preemptible_attempts, 3])\n }\n  output {\n    File output_bam = \"~{sample_name}.bam\"\n    File output_bai = \"~{sample_name}.bai\"\n  }\n}\n\n# HaplotypeCaller per-sample in GVCF mode\ntask HaplotypeCaller {\n  input {\n    # Command parameters\n    File input_bam\n    File input_bam_index\n    File interval_list\n    String output_filename\n    File ref_dict\n    File ref_fasta\n    File ref_fasta_index\n    Float? contamination\n    Boolean make_gvcf\n    Boolean make_bamout\n    Int hc_scatter\n\n    String? gcs_project_for_requester_pays\n\n    String gatk_path\n    String? java_options\n\n    # Runtime parameters\n    String docker\n    Int? mem_gb\n    Int? disk_space_gb\n    Boolean use_ssd = false\n    Int? preemptible_attempts\n  }\n\n  String java_opt = select_first([java_options, \"-XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10\"]) \n\n  Int machine_mem_gb = select_first([mem_gb, 7])\n  Int command_mem_gb = machine_mem_gb - 1\n\n  Float ref_size = size(ref_fasta, \"GB\") + size(ref_fasta_index, \"GB\") + size(ref_dict, \"GB\")\n  Int disk_size = ceil(((size(input_bam, \"GB\") + 30) / hc_scatter) + ref_size) + 20\n\n  String vcf_basename = if make_gvcf then  basename(output_filename, \".gvcf\") else basename(output_filename, \".vcf\")\n  String bamout_arg = if make_bamout then \"-bamout ~{vcf_basename}.bamout.bam\" else \"\"\n\n  parameter_meta {\n    input_bam: {\n      description: \"a bam file\",\n      localization_optional: true\n    }\n    input_bam_index: {\n      description: \"an index file for the bam input\",\n      localization_optional: true\n    }\n  }\n  command {\n    set -e\n  \n    ~{gatk_path} --java-options \"-Xmx~{command_mem_gb}G ~{java_opt}\" \\\n      HaplotypeCaller \\\n      -R ~{ref_fasta} \\\n      -I ~{input_bam} \\\n      -L ~{interval_list} \\\n      -O ~{output_filename} \\\n      -contamination ~{default=\"0\" contamination} \\\n      -G StandardAnnotation -G StandardHCAnnotation ~{true=\"-G AS_StandardAnnotation\" false=\"\" make_gvcf} \\\n      -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 \\\n      ~{true=\"-ERC GVCF\" false=\"\" make_gvcf} \\\n      ~{if defined(gcs_project_for_requester_pays) then \"--gcs-project-for-requester-pays ~{gcs_project_for_requester_pays}\" else \"\"} \\\n      ~{bamout_arg}\n\n    # Cromwell doesn't like optional task outputs, so we have to touch this file.\n    touch ~{vcf_basename}.bamout.bam \n  }\n  runtime {\n    docker: docker\n    memory: machine_mem_gb + \" GB\"\n    disks: \"local-disk \" + select_first([disk_space_gb, disk_size]) + if use_ssd then \" SSD\" else \" HDD\"\n    preemptible: select_first([preemptible_attempts, 3])\n  }\n  output {\n    File output_vcf = \"~{output_filename}\"\n    File output_vcf_index = \"~{output_filename}.tbi\"\n    File bamout = \"~{vcf_basename}.bamout.bam\"\n  }\n}\n# Merge GVCFs generated per-interval for the same sample\ntask MergeGVCFs {\n  input {\n    # Command parameters\n    Array[File] input_vcfs\n    Array[File] input_vcfs_indexes\n    String output_filename\n\n    String gatk_path\n\n    # Runtime parameters\n    String docker\n    Int? mem_gb\n    Int? disk_space_gb\n    Int? preemptible_attempts\n  }\n    Boolean use_ssd = false\n    Int machine_mem_gb = select_first([mem_gb, 3])\n    Int command_mem_gb = machine_mem_gb - 1\n  \n  command {\n  set -e\n\n    ~{gatk_path} --java-options \"-Xmx~{command_mem_gb}G\"  \\\n      MergeVcfs \\\n      --INPUT ~{sep=' --INPUT ' input_vcfs} \\\n      --OUTPUT ~{output_filename}\n  }\n  runtime {\n    docker: docker\n    memory: machine_mem_gb + \" GB\"\n    disks: \"local-disk \" + select_first([disk_space_gb, 100]) + if use_ssd then \" SSD\" else \" HDD\"\n    preemptible: select_first([preemptible_attempts, 3])\n  }\n  output {\n    File output_vcf = \"~{output_filename}\"\n    File output_vcf_index = \"~{output_filename}.tbi\"\n  }\n}\n\n","checksum":[{"checksum":"607eb8e2d551d0c83627e5adf9ec350112bc0e3cd932c4cee2d6c726ff58d564","type":"sha256"}],"url":"https://zenodo.org/api/files/2cab6fd8-4a80-4e73-9e8a-29e7b12cedfc/haplotypecaller-gvcf-gatk4.wdl"}